# ğŸ§  EMNIST Edge Classifier (Mobile Version)

A lightweight, edge-optimized handwritten character recognizer built with PyTorch, trained on the EMNIST dataset, and deployed via Gradio.

---

## ğŸš€ Project Highlights

- ğŸ“¦ **Mobile-Ready Deployment**: Exported as a TorchScript model with only **14,928 parameters** and a **0.24MB** file size.
- âš¡ **Fast & Efficient**: Achieves **1.37 ms** average inference latency with **731.8 FPS throughput**.
- ğŸ§  **Model Accuracy**: 83.8% top-1 accuracy on EMNIST-balanced test set.
- ğŸ“± **Compatibility**: Verified on iPhone 14, Galaxy S23, Raspberry Pi 4B, Jetson Nano.
- ğŸ¨ **Gradio Frontend**: Interactive UI with top-3 prediction visualization and static model info panel.

---

## ğŸ“ Project Structure

```bash
EMNIST-EDGE/
â”œâ”€â”€ images/                  # Example prediction images
â”œâ”€â”€ notebooks/               # Training and optimization notebooks
â”‚   â”œâ”€â”€ EMNIST.ipynb         # Original CNN training (Colab)
â”‚   â””â”€â”€ EMNIST_Edge.ipynb    # Mobile version training + profiling
â”œâ”€â”€ test_samples/            # Manual test images
â”œâ”€â”€ app.py                   # Gradio inference app
â”œâ”€â”€ EdgeCNN_mobile.pt        # TorchScript traced mobile model
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile               # Docker build recipe
â”œâ”€â”€ .dockerignore            # Docker ignore rules
â””â”€â”€ .gitignore               # Git ignore rules
```

---

## ğŸ¯ Usage

```bash
# Step 1: Create conda env (optional)
conda create -n emnist-edge python=3.10
conda activate emnist-edge

# Step 2: Install dependencies
pip install -r requirements.txt

# Step 3: Run app locally
python app.py
```

---

## ğŸ““ Notebooks (Optional)

Training and evaluation workflows are available in the [`notebooks/`](notebooks/) folder, including:

- `EMNIST.ipynb`: Standard CNN for full-size EMNIST
- `EMNIST_Edge.ipynb`: Optimized MobileCNN with quantization, pruning, profiling, and TorchScript tracing

---

## ğŸ” Model Metadata (EdgeCNN_mobile.pt)

| Metric              | Value         |
|---------------------|---------------|
| Parameters          | 14,928        |
| File Size           | 0.24 MB       |
| Accuracy            | 83.8%         |
| Avg Inference Time  | 1.37 ms       |
| P95 Latency         | 1.69 ms       |
| Throughput          | 731.8 FPS     |
| Memory Usage        | 0.22 MB       |
| Production Grade    | âœ… Ready       |

---

## â˜ï¸ Azure Deployment (Gradio on Azure App Service for Containers)

This project is deployed live via Azure App Service using a custom Docker container.

### ğŸ”§ Deployment Summary

- **Platform**: Azure App Service for Containers (Linux)
- **Registry**: Azure Container Registry (ACR)
- **Model**: TorchScript `EdgeCNN_mobile.pt`
- **Frontend**: Gradio served via `app.py`

### ğŸ“¦ Build and Push Docker Image

```bash
# Build image
docker build -t emnist-gradio-app .

# Tag for ACR
docker tag emnist-gradio-app <your-acr-name>.azurecr.io/emnist-gradio-app:v1

# Push to ACR
docker push <your-acr-name>.azurecr.io/emnist-gradio-app:v1
```

### ğŸš€ Deploy to Azure

In Azure Portal:

1. Create Web App â†’ Select **Docker Container**
2. Set `Image Source` to ACR
3. Choose `emnist-gradio-app:v1`
4. Leave startup command blank

ğŸ“Œ *Enable `Always On` to avoid cold start latency*

### ğŸ”— Live Demo (Optional)

Please refer to the following link for live demo. 
> [https://emnidt-edge-container-app-gkevhscfbchub4eq.southeastasia-01.azurewebsites.net/]

---

## ğŸ“Œ Acknowledgements

- Dataset: [EMNIST by Cohen et al.](https://www.nist.gov/itl/products-and-services/emnist-dataset)
- Interface: [Gradio](https://gradio.app)
- Edge Deployment: TorchScript tracing + profiling on Colab

---

## ğŸ§ª Future Work

- ğŸ“± Convert to ONNX and TFLite
- ğŸ“‰ Real-time latency benchmarking from client device
- ğŸ” Auto-update via CI/CD to Azure
